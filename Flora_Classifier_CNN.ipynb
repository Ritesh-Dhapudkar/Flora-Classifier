{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac4da22-2345-472d-a84b-668e30dbe2c2",
   "metadata": {},
   "source": [
    "# Flora Classifier Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d0937-f271-4ce7-b1d3-a8ef32435aa5",
   "metadata": {},
   "source": [
    "## Import Usefull Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb390b9e-a3b1-47c7-896e-261790d3b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfde0b-e41b-4b66-8a22-5e0ea64aad82",
   "metadata": {},
   "source": [
    "## Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae286517-0ecc-4197-9517-caf596db4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset containing flower images\n",
    "base_dir = r\"C:\\Users\\Bhawna B Dhapudkar\\Desktop\\Ritesh Ai\\Ritesh D2\\PROJECTS\\COMPLETED\\DL Model\\Flowers_Group\"\n",
    "\n",
    "# Image size and batch size for training\n",
    "img_size = 224\n",
    "batch = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344eadc1-1b7f-420f-a187-3e61c0b9052c",
   "metadata": {},
   "source": [
    "## Data Augmentation and Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f777e5d-0068-4fe7-9f4d-cf8bd3f6a3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2615 images belonging to 4 classes.\n",
      "Found 650 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Data Augmentation ---------------- #\n",
    "# Creating an ImageDataGenerator for training with augmentation techniques\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,   # Normalize pixel values between 0 and 1\n",
    "    shear_range=0.2,     # Apply random shearing\n",
    "    zoom_range=0.2,      # Apply random zooming\n",
    "    horizontal_flip=True,  # Flip images horizontally\n",
    "    validation_split=0.2  # Split dataset (20% for validation)\n",
    ")\n",
    "\n",
    "# Creating an ImageDataGenerator for testing (only rescaling)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values between 0 and 1\n",
    "    validation_split=0.2  # Split dataset (20% for validation)\n",
    ")\n",
    "\n",
    "# ---------------- Loading Datasets ---------------- #\n",
    "# Load training dataset from directory\n",
    "train_datagen = train_datagen.flow_from_directory(\n",
    "    base_dir, \n",
    "    target_size=(img_size, img_size),  # Resize images to 224x224\n",
    "    subset='training',  \n",
    "    batch_size=batch\n",
    ")\n",
    "\n",
    "# Load validation dataset from directory\n",
    "test_datagen = test_datagen.flow_from_directory(\n",
    "    base_dir,  \n",
    "    target_size=(img_size, img_size),  # Resize images to 224x224\n",
    "    subset='validation',  \n",
    "    batch_size=batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef22ad-2d76-4f22-b4fc-7b78a45a65e4",
   "metadata": {},
   "source": [
    "## CNN Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2be98fc7-651d-4be4-89ea-218d0bbeaa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhawna B Dhapudkar\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ---------------- CNN Model Creation ---------------- #\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Downsampling\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))  # Downsampling\n",
    "\n",
    "# Third Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))  # Downsampling\n",
    "\n",
    "# Fourth Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))  # Downsampling\n",
    "\n",
    "# Flatten the feature maps into a 1D vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with 512 neurons\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))  # Activation function for non-linearity\n",
    "\n",
    "# Output layer with softmax activation (5 classes)\n",
    "model.add(Dense(4, activation=\"softmax\"))  # 4 flower categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481e8a2-8209-4117-86a9-681a215a55cd",
   "metadata": {},
   "source": [
    "## Compilation and Training of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a524251-738d-4ee4-9829-4c2e9718a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3551 - loss: 1.4899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhawna B Dhapudkar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.3573 - loss: 1.4838 - val_accuracy: 0.5985 - val_loss: 0.9668\n",
      "Epoch 2/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.6334 - loss: 0.8956 - val_accuracy: 0.6508 - val_loss: 0.8694\n",
      "Epoch 3/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.6447 - loss: 0.8492 - val_accuracy: 0.6646 - val_loss: 0.8403\n",
      "Epoch 4/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.6936 - loss: 0.7776 - val_accuracy: 0.6308 - val_loss: 0.8572\n",
      "Epoch 5/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.6734 - loss: 0.7845 - val_accuracy: 0.6723 - val_loss: 0.8105\n",
      "Epoch 6/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7098 - loss: 0.7215 - val_accuracy: 0.6846 - val_loss: 0.7893\n",
      "Epoch 7/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 3s/step - accuracy: 0.7352 - loss: 0.6691 - val_accuracy: 0.6985 - val_loss: 0.8045\n",
      "Epoch 8/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.7404 - loss: 0.6426 - val_accuracy: 0.6569 - val_loss: 0.8338\n",
      "Epoch 9/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.7549 - loss: 0.6016 - val_accuracy: 0.6754 - val_loss: 0.8284\n",
      "Epoch 10/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.7664 - loss: 0.5813 - val_accuracy: 0.6923 - val_loss: 0.7752\n",
      "Epoch 11/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.7834 - loss: 0.5443 - val_accuracy: 0.6785 - val_loss: 0.8547\n",
      "Epoch 12/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - accuracy: 0.7954 - loss: 0.5092 - val_accuracy: 0.7062 - val_loss: 0.8564\n",
      "Epoch 13/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3s/step - accuracy: 0.8115 - loss: 0.4586 - val_accuracy: 0.6646 - val_loss: 0.8762\n",
      "Epoch 14/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8067 - loss: 0.4815 - val_accuracy: 0.7338 - val_loss: 0.7598\n",
      "Epoch 15/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8453 - loss: 0.3916 - val_accuracy: 0.7154 - val_loss: 0.7682\n",
      "Epoch 16/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.8747 - loss: 0.3344 - val_accuracy: 0.7031 - val_loss: 0.9844\n",
      "Epoch 17/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.8672 - loss: 0.3406 - val_accuracy: 0.6985 - val_loss: 0.8493\n",
      "Epoch 18/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.8808 - loss: 0.3151 - val_accuracy: 0.6985 - val_loss: 1.0684\n",
      "Epoch 19/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.2473 - val_accuracy: 0.7108 - val_loss: 0.9550\n",
      "Epoch 20/20\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9014 - loss: 0.2733 - val_accuracy: 0.7338 - val_loss: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18d191379e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Model Compilation ---------------- #\n",
    "# Compile the model using Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---------------- Model Training ---------------- #\n",
    "# Train the model for 20 epochs with validation data\n",
    "model.fit(train_datagen, epochs=20, validation_data=test_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f14a6c-8ee1-445e-b794-c8cb5cf8f91b",
   "metadata": {},
   "source": [
    "## Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b837de-202b-4539-bb93-aedb031579be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Save and Load Model ---------------- #\n",
    "# Save the trained model to a file\n",
    "model.save('Flora_Model.h5')\n",
    "\n",
    "# Load the saved model\n",
    "savedModel = load_model('Flora_Model.h5')\n",
    "\n",
    "# Print the class indices (label mappings)\n",
    "print(train_datagen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb5dc4-7a21-4b08-a871-4b861b3e2f44",
   "metadata": {},
   "source": [
    "## Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f13d3-0835-4cbf-9695-c7267f4dd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Image Prediction ---------------- #\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Define a list of class labels corresponding to index positions\n",
    "list_ = ['Daisy', 'Rose', 'Sunflower', 'Tulip']\n",
    "\n",
    "# Load an image for prediction\n",
    "test_image = image.load_img(\n",
    "    r\"C:\\Users\\Bhawna B Dhapudkar\\Desktop\\Ritesh Ai\\Ritesh D2\\PROJECTS\\COMPLETED\\DL Model\\Flowers_Group\\img.jpg\",\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(test_image)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)  # Expand dimensions to match model input shape\n",
    "\n",
    "# Predict the class probabilities\n",
    "result = savedModel.predict(test_image)\n",
    "print(result)  # Print probability values for each class\n",
    "\n",
    "# ---------------- Mapping Prediction to Label ---------------- #\n",
    "# Find the indexof the highest probability\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Print the corresponding class label\n",
    "print(\"Predicted Flower:\", list_[predicted_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
